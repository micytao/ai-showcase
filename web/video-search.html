<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Traffic Video Analysis - RHAIIS</title>
    <link rel="icon" type="image/png" href="../assets/ai-showcase.png">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet">
    <style>
        :root {
            /* Light theme colors */
            --primary-color: #dc2626;
            --primary-hover: #b91c1c;
            --secondary-color: #f3f4f6;
            --success-color: #10b981;
            --success-hover: #059669;
            --danger-color: #ef4444;
            --danger-hover: #dc2626;
            --warning-color: #f59e0b;
            --text-primary: #111827;
            --text-secondary: #6b7280;
            --text-muted: #9ca3af;
            --bg-primary: #ffffff;
            --bg-secondary: #f9fafb;
            --bg-tertiary: #f3f4f6;
            --border-color: #e5e7eb;
            --border-focus: #dc2626;
            --shadow-sm: 0 1px 2px 0 rgb(0 0 0 / 0.05);
            --shadow-md: 0 4px 6px -1px rgb(0 0 0 / 0.1), 0 2px 4px -2px rgb(0 0 0 / 0.1);
            --shadow-lg: 0 10px 15px -3px rgb(0 0 0 / 0.1), 0 4px 6px -4px rgb(0 0 0 / 0.1);
            --shadow-xl: 0 20px 25px -5px rgb(0 0 0 / 0.1), 0 8px 10px -6px rgb(0 0 0 / 0.1);
            --radius-sm: 0.375rem;
            --radius-md: 0.5rem;
            --radius-lg: 0.75rem;
            --radius-xl: 1rem;
        }

        [data-theme="dark"] {
            --primary-color: #f87171;
            --primary-hover: #dc2626;
            --secondary-color: #374151;
            --success-color: #34d399;
            --success-hover: #10b981;
            --danger-color: #f87171;
            --danger-hover: #ef4444;
            --warning-color: #fbbf24;
            --text-primary: #f9fafb;
            --text-secondary: #d1d5db;
            --text-muted: #9ca3af;
            --bg-primary: #1f2937;
            --bg-secondary: #111827;
            --bg-tertiary: #374151;
            --border-color: #4b5563;
            --border-focus: #f87171;
            --shadow-sm: 0 1px 2px 0 rgb(0 0 0 / 0.3);
            --shadow-md: 0 4px 6px -1px rgb(0 0 0 / 0.4), 0 2px 4px -2px rgb(0 0 0 / 0.4);
            --shadow-lg: 0 10px 15px -3px rgb(0 0 0 / 0.4), 0 4px 6px -4px rgb(0 0 0 / 0.4);
            --shadow-xl: 0 20px 25px -5px rgb(0 0 0 / 0.4), 0 8px 10px -6px rgb(0 0 0 / 0.4);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, var(--bg-secondary) 0%, var(--bg-tertiary) 100%);
            color: var(--text-primary);
            min-height: 100vh;
            transition: all 0.3s ease;
        }

        .container {
            max-width: 1600px;
            margin: 0 auto;
            padding: 2rem;
            display: grid;
            gap: 2rem;
            grid-template-areas: 
                "header header"
                "video controls"
                "prompt prompt"
                "analysis analysis";
            grid-template-columns: 1.2fr 1fr;
            grid-template-rows: auto auto auto 1fr;
        }

        @media (max-width: 1200px) {
            .container {
                grid-template-areas: 
                    "header"
                    "video"
                    "controls"
                    "prompt"
                    "analysis";
                grid-template-columns: 1fr;
            }
        }

        .header {
            grid-area: header;
            display: flex;
            justify-content: space-between;
            align-items: center;
            background: var(--bg-primary);
            padding: 1.5rem 2rem;
            border-radius: var(--radius-xl);
            box-shadow: var(--shadow-md);
            border: 1px solid var(--border-color);
        }

        .header h1 {
            font-size: 2rem;
            font-weight: 700;
            background: linear-gradient(135deg, var(--primary-color), var(--success-color));
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            display: flex;
            align-items: center;
            gap: 0.75rem;
        }

        .enterprise-badge {
            background: linear-gradient(135deg, var(--primary-color), var(--primary-hover));
            color: white;
            padding: 0.25rem 0.75rem;
            border-radius: var(--radius-md);
            font-size: 0.75rem;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            margin-left: 1rem;
        }

        .header-actions {
            display: flex;
            gap: 0.5rem;
            align-items: center;
        }

        .theme-toggle {
            background: var(--bg-secondary);
            border: 1px solid var(--border-color);
            border-radius: var(--radius-lg);
            padding: 0.75rem;
            cursor: pointer;
            transition: all 0.3s ease;
            color: var(--text-secondary);
            font-size: 1.25rem;
        }

        .theme-toggle:hover {
            background: var(--bg-tertiary);
            color: var(--primary-color);
            transform: translateY(-1px);
        }

        .video-section {
            grid-area: video;
            background: var(--bg-primary);
            border-radius: var(--radius-xl);
            padding: 2rem;
            box-shadow: var(--shadow-lg);
            border: 1px solid var(--border-color);
            display: flex;
            flex-direction: column;
            gap: 1rem;
        }

        .video-section h3 {
            font-size: 1.25rem;
            font-weight: 600;
            color: var(--text-primary);
            display: flex;
            align-items: center;
            gap: 0.75rem;
            margin-bottom: 0.5rem;
        }

        #trafficVideo {
            width: 100%;
            border-radius: var(--radius-lg);
            background: #000;
            box-shadow: var(--shadow-md);
            transition: all 0.3s ease;
        }

        #trafficVideo:hover {
            transform: scale(1.01);
            box-shadow: var(--shadow-xl);
        }

        .video-controls {
            display: flex;
            gap: 0.5rem;
            align-items: center;
            justify-content: center;
            margin-top: 1rem;
        }

        .video-btn {
            padding: 0.5rem 1rem;
            border: 1px solid var(--border-color);
            border-radius: var(--radius-md);
            background: var(--bg-secondary);
            color: var(--text-secondary);
            cursor: pointer;
            transition: all 0.3s ease;
            font-weight: 600;
            font-size: 0.875rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .video-btn:hover {
            background: var(--primary-color);
            color: white;
            border-color: var(--primary-color);
        }

        .controls-section {
            grid-area: controls;
            background: var(--bg-primary);
            border-radius: var(--radius-xl);
            padding: 2rem;
            box-shadow: var(--shadow-lg);
            border: 1px solid var(--border-color);
            display: flex;
            flex-direction: column;
            gap: 1.5rem;
        }

        .control-group {
            display: flex;
            flex-direction: column;
            gap: 0.75rem;
        }

        .control-group label {
            font-weight: 600;
            color: var(--text-primary);
            font-size: 0.875rem;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        select, input[type="text"] {
            width: 100%;
            padding: 0.875rem 1rem;
            border: 2px solid var(--border-color);
            border-radius: var(--radius-md);
            background: var(--bg-secondary);
            color: var(--text-primary);
            font-size: 0.875rem;
            font-family: inherit;
            transition: all 0.3s ease;
            appearance: none;
        }

        select:focus, input[type="text"]:focus {
            outline: none;
            border-color: var(--border-focus);
            box-shadow: 0 0 0 3px rgb(220 38 38 / 0.1);
            background: var(--bg-primary);
        }

        select {
            background-image: url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' fill='none' viewBox='0 0 20 20'%3e%3cpath stroke='%236b7280' stroke-linecap='round' stroke-linejoin='round' stroke-width='1.5' d='m6 8 4 4 4-4'/%3e%3c/svg%3e");
            background-position: right 0.75rem center;
            background-repeat: no-repeat;
            background-size: 1.5em 1.5em;
            padding-right: 2.5rem;
        }

        .btn {
            display: inline-flex;
            align-items: center;
            justify-content: center;
            gap: 0.5rem;
            padding: 1rem 2rem;
            border: none;
            border-radius: var(--radius-md);
            font-size: 1rem;
            font-weight: 600;
            font-family: inherit;
            cursor: pointer;
            transition: all 0.3s ease;
            text-decoration: none;
            position: relative;
            overflow: hidden;
        }

        .btn::before {
            content: '';
            position: absolute;
            top: 0;
            left: -100%;
            width: 100%;
            height: 100%;
            background: linear-gradient(90deg, transparent, rgba(255,255,255,0.2), transparent);
            transition: left 0.5s;
        }

        .btn:hover::before {
            left: 100%;
        }

        .btn-primary {
            background: linear-gradient(135deg, var(--success-color), var(--success-hover));
            color: white;
            box-shadow: var(--shadow-md);
        }

        .btn-primary:hover {
            background: linear-gradient(135deg, var(--success-hover), var(--success-color));
            transform: translateY(-2px);
            box-shadow: var(--shadow-lg);
        }

        .btn:disabled {
            opacity: 0.6;
            cursor: not-allowed;
            transform: none !important;
        }

        .btn-secondary {
            background: var(--bg-secondary);
            color: var(--text-primary);
            border: 1px solid var(--border-color);
        }

        .btn-secondary:hover {
            background: var(--bg-tertiary);
            color: var(--text-primary);
            border-color: var(--primary-color);
        }

        .input-wrapper {
            position: relative;
        }

        input[type="password"] {
            width: 100%;
            padding: 0.875rem 1rem;
            border: 2px solid var(--border-color);
            border-radius: var(--radius-md);
            background: var(--bg-secondary);
            color: var(--text-primary);
            font-size: 0.875rem;
            font-family: inherit;
            transition: all 0.3s ease;
        }

        input[type="password"]:focus {
            outline: none;
            border-color: var(--border-focus);
            box-shadow: 0 0 0 3px rgb(220 38 38 / 0.1);
            background: var(--bg-primary);
        }

        .prompt-section {
            grid-area: prompt;
            background: var(--bg-primary);
            border-radius: var(--radius-xl);
            padding: 2rem;
            box-shadow: var(--shadow-lg);
            border: 1px solid var(--border-color);
            display: flex;
            flex-direction: column;
            gap: 1rem;
        }

        .prompt-section h3 {
            font-size: 1.25rem;
            font-weight: 600;
            color: var(--text-primary);
            display: flex;
            align-items: center;
            gap: 0.75rem;
            margin-bottom: 0.5rem;
        }

        textarea {
            width: 100%;
            min-height: 120px;
            padding: 1rem;
            border: 2px solid var(--border-color);
            border-radius: var(--radius-md);
            background: var(--bg-secondary);
            color: var(--text-primary);
            font-size: 0.875rem;
            font-family: inherit;
            resize: vertical;
            transition: all 0.3s ease;
        }

        textarea:focus {
            outline: none;
            border-color: var(--border-focus);
            box-shadow: 0 0 0 3px rgb(220 38 38 / 0.1);
            background: var(--bg-primary);
        }

        .analysis-section {
            grid-area: analysis;
            background: var(--bg-primary);
            border-radius: var(--radius-xl);
            padding: 2rem;
            box-shadow: var(--shadow-lg);
            border: 1px solid var(--border-color);
            display: flex;
            flex-direction: column;
            gap: 1rem;
        }

        .analysis-section h3 {
            font-size: 1.25rem;
            font-weight: 600;
            color: var(--text-primary);
            display: flex;
            align-items: center;
            gap: 0.75rem;
            margin-bottom: 0.5rem;
        }

        .status-indicator {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            border-radius: var(--radius-lg);
            font-size: 0.875rem;
            font-weight: 500;
        }

        .status-ready {
            background: rgba(16, 185, 129, 0.1);
            color: var(--success-color);
            border: 1px solid rgba(16, 185, 129, 0.2);
        }

        .status-processing {
            background: rgba(245, 158, 11, 0.1);
            color: var(--warning-color);
            border: 1px solid rgba(245, 158, 11, 0.2);
        }

        .status-error {
            background: rgba(239, 68, 68, 0.1);
            color: var(--danger-color);
            border: 1px solid rgba(239, 68, 68, 0.2);
        }

        .pulse {
            animation: pulse 2s infinite;
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }

        .spinner {
            display: inline-block;
            width: 1rem;
            height: 1rem;
            border: 2px solid rgba(255,255,255,0.3);
            border-radius: 50%;
            border-top-color: currentColor;
            animation: spin 1s ease-in-out infinite;
        }

        @keyframes spin {
            to { transform: rotate(360deg); }
        }

        .metrics-grid {
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 0.5rem;
            margin-top: 1rem;
        }
        
        @media (max-width: 768px) {
            .metrics-grid {
                grid-template-columns: repeat(2, 1fr);
            }
        }

        .metric-card {
            background: var(--bg-secondary);
            border: 1px solid var(--border-color);
            border-radius: var(--radius-md);
            padding: 0.75rem;
            text-align: center;
            transition: all 0.3s ease;
        }

        .metric-card:hover {
            border-color: var(--success-color);
            transform: translateY(-1px);
            box-shadow: 0 4px 12px rgba(16, 185, 129, 0.1);
        }

        .metric-label {
            font-size: 0.65rem;
            color: var(--text-secondary);
            text-transform: uppercase;
            letter-spacing: 0.05em;
            margin-bottom: 0.25rem;
        }

        .metric-value {
            font-size: 1.1rem;
            font-weight: 700;
            color: var(--text-primary);
            line-height: 1;
        }

        .streaming-indicator {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            color: var(--success-color);
            font-size: 0.875rem;
            margin-left: 0.5rem;
        }

        .streaming-indicator .dot {
            width: 8px;
            height: 8px;
            background: var(--success-color);
            border-radius: 50%;
            animation: pulse 1.5s ease-in-out infinite;
        }

        .enterprise-info {
            background: linear-gradient(135deg, rgba(220, 38, 38, 0.1), rgba(239, 68, 68, 0.05));
            border: 1px solid rgba(220, 38, 38, 0.2);
            border-radius: var(--radius-md);
            padding: 1rem;
            margin-top: 1rem;
            font-size: 0.75rem;
            color: var(--text-secondary);
        }

        .enterprise-info strong {
            color: var(--primary-color);
        }

        ::-webkit-scrollbar {
            width: 8px;
        }

        ::-webkit-scrollbar-track {
            background: var(--bg-secondary);
            border-radius: var(--radius-sm);
        }

        ::-webkit-scrollbar-thumb {
            background: var(--border-color);
            border-radius: var(--radius-sm);
        }

        ::-webkit-scrollbar-thumb:hover {
            background: var(--text-muted);
        }

        .fade-in {
            animation: fadeIn 0.5s ease-in;
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }
    </style>
</head>
<body>
    <div class="container">
        <header class="header">
            <h1>
                <i class="fas fa-traffic-light"></i>
                Traffic Video Analysis
                <span class="enterprise-badge">RHAIIS</span>
            </h1>
            <div class="header-actions">
                <button class="theme-toggle" id="settingsToggle" title="Open Settings">
                    <i class="fas fa-cog"></i>
                </button>
                <button class="theme-toggle" id="themeToggle" title="Toggle dark mode">
                    <i class="fas fa-moon"></i>
                </button>
            </div>
        </header>

        <div class="video-section">
            <h3>
                <i class="fas fa-video"></i>
                Traffic Camera Feed
            </h3>
            <video id="trafficVideo" controls crossorigin="anonymous">
                <source src="../assets/traffic_camera.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <div class="video-controls">
                <button class="video-btn" onclick="captureCurrentFrame()">
                    <i class="fas fa-camera"></i>
                    Capture Frame
                </button>
                <button class="video-btn" onclick="resetVideo()">
                    <i class="fas fa-redo"></i>
                    Reset Video
                </button>
            </div>
            <div id="videoStatus" class="status-indicator status-ready">
                <i class="fas fa-circle"></i>
                <span>Video ready</span>
            </div>
        </div>

        <div class="controls-section">
            <div class="control-group">
                <label for="vllmEndpointSelect">
                    <i class="fas fa-server"></i>
                    RHAIIS vLLM Endpoint
                </label>
                <select id="vllmEndpointSelect" onchange="handleVllmEndpointChange()">
                    <option value="https://rhaiis-route-rhaiis.apps.cluster-pjc5d.pjc5d.sandbox1225.opentlc.com">Embedded Model (Default)</option>
                    <option value="maas">MaaS (Configured Models)</option>
                    <option value="custom">Custom Endpoint...</option>
                </select>
                <div id="customVllmEndpointWrapper" style="display: none; margin-top: 0.5rem;">
                    <div class="input-wrapper">
                        <input type="text" id="baseURL" placeholder="Enter custom endpoint URL (e.g., https://api.openai.com)">
                    </div>
                    <div class="input-wrapper" style="margin-top: 0.5rem;">
                        <input type="password" id="apiKey" placeholder="API Key (optional - required for some endpoints)">
                    </div>
                    <div class="input-wrapper" style="margin-top: 0.5rem;">
                        <button id="fetchModelsBtn" class="btn btn-secondary" onclick="fetchAvailableModels()" style="width: 100%; padding: 0.75rem 1rem; font-size: 0.875rem;">
                            <i class="fas fa-download"></i>
                            <span>Fetch Available Models</span>
                        </button>
                    </div>
                    <div class="input-wrapper" style="margin-top: 0.5rem;">
                        <select id="modelSelect" disabled>
                            <option value="">Select a model (fetch models first)</option>
                        </select>
                    </div>
                </div>
                <div id="maasVllmEndpointWrapper" style="display: none; margin-top: 0.5rem;">
                    <div class="input-wrapper">
                        <select id="maasModelSelect" onchange="handleMaasModelSelection()">
                            <option value="">-- Select a configured model --</option>
                        </select>
                    </div>
                    <div id="maasModelInfo" style="display: none; margin-top: 0.5rem; padding: 0.75rem; background: var(--bg-secondary); border-radius: var(--radius-md); border: 1px solid var(--border-color); font-size: 0.875rem;">
                        <div style="color: var(--text-primary); font-weight: 600; margin-bottom: 0.5rem;">
                            <i class="fas fa-info-circle"></i> Selected Model Details
                        </div>
                        <div style="color: var(--text-secondary);">
                            <strong>Name:</strong> <span id="maasModelName">-</span><br>
                            <strong>Endpoint:</strong> <span id="maasModelEndpoint">-</span><br>
                            <strong>Model:</strong> <span id="maasModelId">-</span><br>
                            <strong>Status:</strong> <span id="maasModelStatus" style="color: var(--success-color);">‚úì Tested Successfully</span>
                        </div>
                    </div>
                </div>
                <div class="enterprise-info">
                    <strong>üè¢ Enterprise Setup:</strong> Using Red Hat AI Inference Server (RHAIIS) with vLLM backend.<br>
                    <strong>Model:</strong> Qwen2-VL-2B-Instruct (Vision Language Model)<br>
                    <strong>API:</strong> OpenAI-compatible (Port 8000)
                </div>
            </div>

            <div class="control-group">
                <button id="testConnectionBtn" class="btn btn-primary" onclick="testConnection()" style="width: 100%; margin-bottom: 1rem;">
                    <i class="fas fa-wifi"></i>
                    <span>Test VLM Connection</span>
                </button>
            </div>

            <button id="analyzeFrameBtn" class="btn btn-primary" onclick="analyzeCurrentFrame()" style="width: 100%; margin-bottom: 0.5rem;">
                <i class="fas fa-camera"></i>
                <span>Analyze Current Frame</span>
            </button>

            <button id="analyzeClipBtn" class="btn btn-primary" onclick="analyzeVideoClip()" style="width: 100%;">
                <i class="fas fa-film"></i>
                <span>Analyze Video Clip</span>
            </button>

            <div class="control-group" style="margin-top: 1rem;">
                <label>
                    <i class="fas fa-tachometer-alt"></i>
                    Performance Metrics
                </label>
                <div class="metrics-grid">
                    <div class="metric-card">
                        <div class="metric-label">TTFT</div>
                        <div class="metric-value" id="ttft">--</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-label">Total Time</div>
                        <div class="metric-value" id="totalTime">--</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-label">Tokens/s</div>
                        <div class="metric-value" id="tokensPerSecond">--</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-label">Video FPS</div>
                        <div class="metric-value" id="videoFPS">--</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-label">Frame Time</div>
                        <div class="metric-value" id="frameTime">--</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-label">Resolution</div>
                        <div class="metric-value" id="videoResolution">--</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-label">Total Tokens</div>
                        <div class="metric-value" id="totalTokens">--</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-label">Prompt Tokens</div>
                        <div class="metric-value" id="promptTokens">--</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-label">Response</div>
                        <div class="metric-value" id="responseTokens">--</div>
                    </div>
                </div>
            </div>
        </div>

        <div class="prompt-section">
            <h3>
                <i class="fas fa-comment-dots"></i>
                Analysis Prompt
            </h3>
            <textarea id="promptText" placeholder="Enter your analysis prompt here...">You are an intelligent traffic monitoring system. Analyze the provided image(s) where each vehicle is overlaid with an ID. Identify and describe all traffic-related events, including timestamps and vehicle IDs when applicable.</textarea>
        </div>

        <div class="analysis-section">
            <h3>
                <i class="fas fa-robot"></i>
                VLM Analysis Results
                <span id="streamingIndicator" class="streaming-indicator" style="display: none;">
                    <span class="dot"></span>
                    <span>Streaming</span>
                </span>
            </h3>
            <div id="statusIndicator" class="status-indicator status-ready">
                <i class="fas fa-circle"></i>
                <span>Ready to analyze</span>
            </div>
            <textarea id="responseText" style="min-height: 300px;" placeholder="Analysis results will appear here...">Analysis results will appear here...</textarea>
            
            <div class="control-group" style="margin-top: 1rem;">
                <label style="font-size: 0.75rem;">
                    <i class="fas fa-chart-line"></i>
                    Performance Summary
                </label>
                <div class="enterprise-info" style="font-family: monospace; font-size: 0.75rem; line-height: 1.6;">
                    <div><strong>‚ö° TTFT (Time to First Token):</strong> <span id="summaryTTFT">--</span></div>
                    <div><strong>‚è±Ô∏è Total Processing Time:</strong> <span id="summaryTotalTime">--</span></div>
                    <div><strong>üöÄ Throughput:</strong> <span id="summaryThroughput">--</span></div>
                    <div><strong>üé¨ Video:</strong> <span id="summaryVideoFPS">--</span> FPS @ <span id="summaryFrameTime">--</span> | <span id="summaryVideoResolution">--</span></div>
                    <div><strong>üìä Tokens:</strong> Prompt: <span id="summaryPromptTokens">--</span> | Response: <span id="summaryResponseTokens">--</span> | Total: <span id="summaryTotalTokens">--</span></div>
                </div>
            </div>
        </div>
    </div>

    <canvas id="canvas" style="display: none;"></canvas>

    <script>
        const video = document.getElementById('trafficVideo');
        const canvas = document.getElementById('canvas');
        const baseURLInput = document.getElementById('baseURL');
        const promptText = document.getElementById('promptText');
        const responseText = document.getElementById('responseText');
        const statusIndicator = document.getElementById('statusIndicator');
        const videoStatus = document.getElementById('videoStatus');
        const themeToggle = document.getElementById('themeToggle');
        const settingsToggle = document.getElementById('settingsToggle');
        const analyzeFrameBtn = document.getElementById('analyzeFrameBtn');
        const analyzeClipBtn = document.getElementById('analyzeClipBtn');

        let currentFrameData = null;

        // Set default endpoint
        baseURLInput.value = "https://rhaiis-route-rhaiis.apps.cluster-pjc5d.pjc5d.sandbox1225.opentlc.com";

        // Theme management
        function initTheme() {
            const savedTheme = localStorage.getItem('theme') || 'light';
            document.documentElement.setAttribute('data-theme', savedTheme);
            updateThemeIcon(savedTheme);
        }

        function updateThemeIcon(theme) {
            const icon = themeToggle.querySelector('i');
            icon.className = theme === 'dark' ? 'fas fa-sun' : 'fas fa-moon';
        }

        function toggleTheme() {
            const currentTheme = document.documentElement.getAttribute('data-theme');
            const newTheme = currentTheme === 'dark' ? 'light' : 'dark';
            
            document.documentElement.setAttribute('data-theme', newTheme);
            localStorage.setItem('theme', newTheme);
            updateThemeIcon(newTheme);
        }

        themeToggle.addEventListener('click', toggleTheme);

        // Settings button click handler
        settingsToggle.addEventListener('click', () => {
            window.open('settings.html', '_blank');
        });

        // MaaS Model Management
        let selectedMaasConfig = null;

        // Load available MaaS models from settings
        function loadMaasModels() {
            const maasSelect = document.getElementById('maasModelSelect');
            const maasInfo = document.getElementById('maasModelInfo');
            
            // Clear existing options except the first one
            maasSelect.innerHTML = '<option value="">-- Select a configured model --</option>';
            maasInfo.style.display = 'none';
            selectedMaasConfig = null;
            
            // Load models from localStorage (from settings.html)
            const models = [];
            
            // Load VLM endpoint
            const vlmEndpoint = localStorage.getItem('vlmEndpoint');
            const vlmApiKey = localStorage.getItem('vlmApiKey');
            const vlmModel = localStorage.getItem('vlmModel');
            
            if (vlmEndpoint && vlmApiKey) {
                models.push({
                    id: 'vlm_primary',
                    name: 'VLM Primary',
                    endpoint: vlmEndpoint,
                    apiKey: vlmApiKey,
                    model: vlmModel || 'Qwen/Qwen2-VL-2B-Instruct',
                    type: 'vlm'
                });
            }
            
            // Load custom endpoints
            try {
                const customEndpoints = JSON.parse(localStorage.getItem('customEndpoints') || '[]');
                customEndpoints.forEach(endpoint => {
                    const endpointUrl = localStorage.getItem(`${endpoint.id}Endpoint`) || endpoint.endpoint;
                    const apiKey = localStorage.getItem(`${endpoint.id}ApiKey`) || endpoint.apiKey;
                    const model = localStorage.getItem(`${endpoint.id}Model`) || '';
                    
                    if (endpointUrl && apiKey) {
                        models.push({
                            id: endpoint.id,
                            name: endpoint.name,
                            endpoint: endpointUrl,
                            apiKey: apiKey,
                            model: model,
                            type: 'custom'
                        });
                    }
                });
            } catch (error) {
                console.error('Error loading custom endpoints:', error);
            }
            
            // Populate dropdown
            if (models.length === 0) {
                const option = document.createElement('option');
                option.value = '';
                option.textContent = 'No configured models found - Configure in Settings';
                option.disabled = true;
                maasSelect.appendChild(option);
                
                updateStatus('error', 'No MaaS models configured', 'exclamation-triangle');
                responseText.value = '‚ùå No configured models found.\n\nPlease go to Settings and configure at least one model endpoint with API key and test it successfully.';
            } else {
                models.forEach(model => {
                    const option = document.createElement('option');
                    option.value = model.id;
                    option.textContent = `${model.name} (${model.model || 'Default Model'})`;
                    option.dataset.config = JSON.stringify(model);
                    maasSelect.appendChild(option);
                });
                
                updateStatus('ready', `Found ${models.length} configured model(s)`, 'check-circle');
                responseText.value = `‚úÖ Found ${models.length} configured model(s).\n\nSelect a model from the dropdown to use it.`;
            }
            
            console.log('üìã Loaded MaaS models:', models);
        }

        // Handle MaaS model selection
        function handleMaasModelSelection() {
            const maasSelect = document.getElementById('maasModelSelect');
            const maasInfo = document.getElementById('maasModelInfo');
            const selectedOption = maasSelect.options[maasSelect.selectedIndex];
            
            if (!selectedOption || !selectedOption.value) {
                maasInfo.style.display = 'none';
                selectedMaasConfig = null;
                return;
            }
            
            // Parse the configuration
            try {
                selectedMaasConfig = JSON.parse(selectedOption.dataset.config);
                
                // Update info display
                document.getElementById('maasModelName').textContent = selectedMaasConfig.name;
                document.getElementById('maasModelEndpoint').textContent = selectedMaasConfig.endpoint;
                document.getElementById('maasModelId').textContent = selectedMaasConfig.model || 'Default Model';
                maasInfo.style.display = 'block';
                
                // Apply the configuration
                baseURLInput.value = selectedMaasConfig.endpoint;
                
                // Update status
                updateStatus('ready', `Using ${selectedMaasConfig.name}`, 'check-circle');
                responseText.value = `‚úÖ Selected: ${selectedMaasConfig.name}\nEndpoint: ${selectedMaasConfig.endpoint}\nModel: ${selectedMaasConfig.model || 'Default'}\n\nReady to analyze video with VLM.`;
                
                console.log('‚úÖ Selected MaaS config:', selectedMaasConfig);
            } catch (error) {
                console.error('Error parsing MaaS config:', error);
                updateStatus('error', 'Failed to load model config', 'exclamation-triangle');
                responseText.value = '‚ùå Error loading model configuration. Please try again or reconfigure in Settings.';
                selectedMaasConfig = null;
            }
        }

        // Handle vLLM endpoint dropdown change
        function handleVllmEndpointChange() {
            const select = document.getElementById('vllmEndpointSelect');
            const customWrapper = document.getElementById('customVllmEndpointWrapper');
            const maasWrapper = document.getElementById('maasVllmEndpointWrapper');
            
            // Hide both wrappers first
            customWrapper.style.display = 'none';
            maasWrapper.style.display = 'none';
            
            if (select.value === 'custom') {
                customWrapper.style.display = 'block';
                baseURLInput.focus();
            } else if (select.value === 'maas') {
                maasWrapper.style.display = 'block';
                loadMaasModels();
            } else {
                customWrapper.style.display = 'none';
                baseURLInput.value = select.value;
            }
        }

        // Status indicator management
        function updateStatus(type, message, icon = 'circle') {
            statusIndicator.className = `status-indicator status-${type}`;
            statusIndicator.innerHTML = `<i class="fas fa-${icon}"></i><span>${message}</span>`;
            
            if (type === 'processing') {
                statusIndicator.classList.add('pulse');
            } else {
                statusIndicator.classList.remove('pulse');
            }
        }

        function updateVideoStatus(type, message, icon = 'circle') {
            videoStatus.className = `status-indicator status-${type}`;
            videoStatus.innerHTML = `<i class="fas fa-${icon}"></i><span>${message}</span>`;
        }

        // Test connection function
        async function testConnection() {
            const endpoint = baseURLInput.value.trim();
            
            updateStatus('processing', 'Testing vLLM connection...', 'wifi');
            responseText.value = "Testing connection to RHAIIS vLLM endpoint...";

            try {
                const controller = new AbortController();
                const timeoutId = setTimeout(() => controller.abort(), 15000);

                // Get the selected model
                const selectedModel = getSelectedModel();
                console.log('Testing with model:', selectedModel);

                const testPayload = {
                    model: selectedModel,
                    max_tokens: 20,
                    messages: [
                        { role: "user", content: "Hello, can you respond?" }
                    ]
                };

                const apiUrl = endpoint ? `${endpoint}/v1/chat/completions` : '/v1/chat/completions';
                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: getApiHeaders(),
                    mode: 'cors',
                    signal: controller.signal,
                    body: JSON.stringify(testPayload)
                });

                clearTimeout(timeoutId);
                
                if (response.ok) {
                    const data = await response.json();
                    updateStatus('ready', 'vLLM connection successful', 'check-circle');
                    responseText.value = `‚úÖ RHAIIS vLLM connection successful!\nEndpoint: ${endpoint || 'default'}\nModel: ${selectedModel}\nTest Response: ${data.choices?.[0]?.message?.content || 'API responded correctly'}`;
                } else {
                    const errorText = await response.text();
                    updateStatus('ready', 'Server reachable but API error', 'exclamation-triangle');
                    responseText.value = `‚ö†Ô∏è vLLM server reachable but API returned error: ${response.status}\nError: ${errorText}`;
                }
            } catch (error) {
                console.error('vLLM connection test error:', error);
                updateStatus('error', 'vLLM connection failed', 'exclamation-triangle');
                
                if (error.name === 'AbortError') {
                    responseText.value = `‚ùå vLLM connection test timed out after 15 seconds.\n\nPlease check:\n1. Is the RHAIIS vLLM server running?\n2. Is the URL correct?\n3. Are you experiencing network issues?`;
                } else {
                    responseText.value = `‚ùå Connection error: ${error.message}`;
                }
            }
        }

        // Get video FPS (frames per second)
        function getVideoFPS() {
            // Try to get FPS from video metadata
            // Note: Not all browsers expose this, so we'll estimate if needed
            if (video.mozDecodedFrames !== undefined && video.mozPresentedFrames !== undefined) {
                // Firefox
                const fps = video.mozDecodedFrames / video.currentTime;
                return fps.toFixed(2);
            } else if (video.webkitDecodedFrameCount !== undefined) {
                // Chrome/Safari
                const fps = video.webkitDecodedFrameCount / video.currentTime;
                return fps.toFixed(2);
            } else {
                // Fallback: Common video FPS values
                // Most videos are 24, 25, 30, or 60 fps
                return "30"; // Default assumption
            }
        }

        // Capture current frame from video
        function captureCurrentFrame() {
            try {
                // Check if video is loaded (has dimensions)
                if (!video.videoWidth || !video.videoHeight) {
                    updateVideoStatus('error', 'Video not loaded yet', 'exclamation-triangle');
                    return false;
                }

                // Check if video has valid current time
                if (video.readyState < 2) {
                    updateVideoStatus('error', 'Video not ready', 'exclamation-triangle');
                    return false;
                }

                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
                const context = canvas.getContext('2d');
                context.drawImage(video, 0, 0, canvas.width, canvas.height);
                
                // Try to export canvas - this will fail if canvas is tainted
                currentFrameData = canvas.toDataURL('image/jpeg', 0.8);
                
                // Update video metrics
                const fps = getVideoFPS();
                const frameTime = video.currentTime.toFixed(2);
                const resolution = `${video.videoWidth}x${video.videoHeight}`;
                
                document.getElementById('videoFPS').textContent = fps;
                document.getElementById('frameTime').textContent = `${frameTime}s`;
                document.getElementById('videoResolution').textContent = resolution;
                
                document.getElementById('summaryVideoFPS').textContent = fps;
                document.getElementById('summaryFrameTime').textContent = `${frameTime}s`;
                document.getElementById('summaryVideoResolution').textContent = resolution;
                
                updateVideoStatus('ready', `Frame captured @ ${frameTime}s (${fps} FPS)`, 'check-circle');
                console.log('üì∏ Frame captured from video at time:', video.currentTime);
                console.log('   - FPS:', fps);
                console.log('   - Resolution:', resolution);
                return true;
            } catch (error) {
                console.error('‚ùå Failed to capture frame:', error);
                
                if (error.name === 'SecurityError') {
                    updateVideoStatus('error', 'CORS/Security Error', 'exclamation-triangle');
                    alert('‚ùå Security Error: Cannot capture video frame\n\n' +
                          'This is a browser security restriction (CORS/tainted canvas).\n\n' +
                          'Solutions:\n' +
                          '1. Serve the page through a web server (not file://)\n' +
                          '   - Use: python3 -m http.server 8000\n' +
                          '   - Or: npx serve .\n' +
                          '   - Then open: http://localhost:8000/web/video-search.html\n\n' +
                          '2. For Chrome, start with: --allow-file-access-from-files flag\n\n' +
                          '3. Deploy to a proper web server\n\n' +
                          'Current location: ' + window.location.href);
                } else {
                    updateVideoStatus('error', 'Capture failed', 'exclamation-triangle');
                }
                return false;
            }
        }

        // Reset video to beginning
        function resetVideo() {
            video.currentTime = 0;
            video.play();
            updateVideoStatus('ready', 'Video reset', 'redo');
        }

        // Fetch available models from the custom endpoint
        async function fetchAvailableModels() {
            const baseURLInput = document.getElementById('baseURL');
            const modelSelect = document.getElementById('modelSelect');
            const fetchBtn = document.getElementById('fetchModelsBtn');
            
            const endpoint = baseURLInput.value.trim();
            
            if (!endpoint) {
                alert('Please enter a custom endpoint URL first');
                baseURLInput.focus();
                return;
            }
            
            // Show loading state
            fetchBtn.disabled = true;
            fetchBtn.innerHTML = '<i class="fas fa-spinner fa-spin"></i><span>Fetching models...</span>';
            modelSelect.disabled = true;
            modelSelect.innerHTML = '<option value="">Loading models...</option>';
            
            try {
                const controller = new AbortController();
                const timeoutId = setTimeout(() => controller.abort(), 10000); // 10 second timeout
                
                // Build the models API URL
                const modelsUrl = `${endpoint}/v1/models`;
                
                // Use the same headers as API requests (includes API key if provided)
                const headers = getApiHeaders();
                
                console.log('Fetching models from:', modelsUrl);
                
                const response = await fetch(modelsUrl, {
                    method: 'GET',
                    headers: headers,
                    mode: 'cors',
                    signal: controller.signal,
                });
                
                clearTimeout(timeoutId);
                
                if (response.ok) {
                    const data = await response.json();
                    console.log('Models response:', data);
                    
                    // Extract model IDs from the response
                    const models = data.data || data.models || [];
                    
                    if (models.length === 0) {
                        modelSelect.innerHTML = '<option value="">No models found</option>';
                        alert('No models found at this endpoint');
                    } else {
                        modelSelect.innerHTML = '<option value="">Select a model</option>';
                        models.forEach(model => {
                            const option = document.createElement('option');
                            const modelId = model.id || model.name || model;
                            option.value = modelId;
                            option.textContent = modelId;
                            modelSelect.appendChild(option);
                        });
                        modelSelect.disabled = false;
                        
                        // Show success message
                        updateStatus('ready', `Found ${models.length} models`, 'check-circle');
                        responseText.value = `‚úÖ Successfully fetched ${models.length} models from endpoint.\n\nPlease select a model from the dropdown.`;
                    }
                } else {
                    const errorText = await response.text();
                    console.error('Error fetching models:', response.status, errorText);
                    modelSelect.innerHTML = '<option value="">Error fetching models</option>';
                    alert(`Failed to fetch models: ${response.status} ${response.statusText}\n\n${errorText}`);
                }
            } catch (error) {
                console.error('Error fetching models:', error);
                modelSelect.innerHTML = '<option value="">Error - fetch models again</option>';
                
                if (error.name === 'AbortError') {
                    alert('Request timed out after 10 seconds. Please check your endpoint URL.');
                } else if (error.message.includes('Failed to fetch') || error.message.includes('CORS')) {
                    alert('CORS or connection error. Make sure the endpoint allows cross-origin requests.\n\nError: ' + error.message);
                } else {
                    alert('Error fetching models: ' + error.message);
                }
            } finally {
                // Restore button state
                fetchBtn.disabled = false;
                fetchBtn.innerHTML = '<i class="fas fa-download"></i><span>Fetch Available Models</span>';
            }
        }

        // Get the selected model name
        function getSelectedModel() {
            const select = document.getElementById('vllmEndpointSelect');
            
            // If using MaaS and a model is selected, use it
            if (select.value === 'maas' && selectedMaasConfig && selectedMaasConfig.model) {
                console.log('üìã Using MaaS model:', selectedMaasConfig.model);
                return selectedMaasConfig.model;
            }
            
            const modelSelect = document.getElementById('modelSelect');
            
            // If using custom endpoint and a model is selected, use it
            if (select.value === 'custom' && modelSelect.value) {
                return modelSelect.value;
            }
            
            // Otherwise use the default model
            return "Qwen/Qwen2-VL-2B-Instruct";
        }

        // Get API headers
        function getApiHeaders() {
            const headers = {
                'Content-Type': 'application/json',
                'Accept': 'text/event-stream',
            };
            
            const vllmSelect = document.getElementById('vllmEndpointSelect');
            
            // Use MaaS API key if MaaS is selected
            if (vllmSelect.value === 'maas' && selectedMaasConfig && selectedMaasConfig.apiKey) {
                headers['Authorization'] = `Bearer ${selectedMaasConfig.apiKey}`;
                console.log('üîë Using MaaS API key for:', selectedMaasConfig.name);
            } else {
                // Add API key if provided (for custom endpoints)
                const apiKeyInput = document.getElementById('apiKey');
                if (apiKeyInput && apiKeyInput.value.trim()) {
                    headers['Authorization'] = `Bearer ${apiKeyInput.value.trim()}`;
                }
            }
            
            return headers;
        }

        // Send streaming chat completion request to vLLM API
        async function sendChatCompletionRequest(instruction, imageBase64URL, onStreamCallback) {
            const controller = new AbortController();
            const timeoutId = setTimeout(() => controller.abort(), 60000); // Increased to 60 seconds for large videos
            
            try {
                const endpoint = baseURLInput.value.trim();
                const apiUrl = endpoint ? `${endpoint}/v1/chat/completions` : '/v1/chat/completions';
                
                console.log('üì§ Preparing VLM request...');
                console.log('   - Endpoint:', apiUrl);
                console.log('   - Image size:', imageBase64URL.length, 'bytes');
                console.log('   - Instruction length:', instruction.length, 'characters');
                console.log('   - Streaming: ENABLED');
                
                // Get the selected model
                const selectedModel = getSelectedModel();
                console.log('   - Model:', selectedModel);
                
                const payload = {
                    model: selectedModel,
                    max_tokens: 500,
                    temperature: 0.3,
                    messages: [
                        { 
                            role: 'user', 
                            content: [
                                { type: 'text', text: instruction },
                                { 
                                    type: 'image_url', 
                                    image_url: {
                                        url: imageBase64URL,
                                        detail: "auto"
                                    } 
                                }
                            ] 
                        }
                    ],
                    stream: true,  // Enable streaming
                    stream_options: {
                        include_usage: true
                    }
                };
                
                console.log('üì§ Sending streaming request to VLM...');
                
                const requestStartTime = performance.now();
                let firstTokenTime = null;
                let tokenCount = 0;
                let fullResponse = '';
                let usage = null;
                
                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: getApiHeaders(),
                    mode: 'cors',
                    signal: controller.signal,
                    body: JSON.stringify(payload)
                });
                
                clearTimeout(timeoutId);
                
                console.log('üì• Streaming response received. Status:', response.status);
                
                if (!response.ok) {
                    const errorData = await response.text();
                    console.error('‚ùå vLLM server error response:', response.status, errorData);
                    return { error: `vLLM Server error: ${response.status}\n\n${errorData.substring(0, 500)}` };
                }
                
                // Read the streaming response
                const reader = response.body.getReader();
                const decoder = new TextDecoder();
                
                while (true) {
                    const { done, value } = await reader.read();
                    
                    if (done) {
                        console.log('‚úÖ Stream completed');
                        break;
                    }
                    
                    // Decode the chunk
                    const chunk = decoder.decode(value, { stream: true });
                    const lines = chunk.split('\n');
                    
                    for (const line of lines) {
                        if (line.startsWith('data: ')) {
                            const data = line.substring(6).trim();
                            
                            if (data === '[DONE]') {
                                console.log('‚úÖ Stream received [DONE] signal');
                                continue;
                            }
                            
                            try {
                                const parsed = JSON.parse(data);
                                
                                // Capture first token time
                                if (!firstTokenTime && parsed.choices?.[0]?.delta?.content) {
                                    firstTokenTime = performance.now();
                                    const ttft = firstTokenTime - requestStartTime;
                                    console.log(`‚ö° Time to first token: ${ttft.toFixed(0)} ms`);
                                }
                                
                                // Extract content delta
                                const delta = parsed.choices?.[0]?.delta?.content;
                                if (delta) {
                                    fullResponse += delta;
                                    tokenCount++;
                                    
                                    // Call the streaming callback
                                    if (onStreamCallback) {
                                        onStreamCallback(fullResponse, {
                                            tokenCount,
                                            ttft: firstTokenTime ? firstTokenTime - requestStartTime : null,
                                            elapsed: performance.now() - requestStartTime
                                        });
                                    }
                                }
                                
                                // Extract usage information if available
                                if (parsed.usage) {
                                    usage = parsed.usage;
                                    console.log('üìä Usage data received:', usage);
                                }
                                
                            } catch (e) {
                                console.warn('Failed to parse SSE data:', data, e);
                            }
                        }
                    }
                }
                
                const requestEndTime = performance.now();
                const totalTime = requestEndTime - requestStartTime;
                const ttft = firstTokenTime ? firstTokenTime - requestStartTime : totalTime;
                
                console.log('‚úÖ VLM Streaming completed successfully');
                console.log(`   - Total time: ${totalTime.toFixed(0)} ms`);
                console.log(`   - Time to first token: ${ttft.toFixed(0)} ms`);
                console.log(`   - Response length: ${fullResponse.length} characters`);
                console.log(`   - Streaming chunks: ${tokenCount}`);
                
                // Update performance metrics with final data
                updatePerformanceMetrics({
                    totalTime: totalTime,
                    ttft: ttft,
                    tokenCount: tokenCount,
                    usage: usage || {}
                });
                
                return fullResponse;
                
            } catch (error) {
                clearTimeout(timeoutId);
                console.error('‚ùå vLLM fetch error details:', error);
                console.error('   - Error name:', error.name);
                console.error('   - Error message:', error.message);
                console.error('   - Error stack:', error.stack);
                
                if (error.name === 'AbortError') {
                    return { error: 'Request timed out after 60 seconds. The VLM may be processing a large image or experiencing high load.' };
                } else if (error.message.includes('Failed to fetch')) {
                    return { error: `Network error: Unable to connect to VLM endpoint.\n\nPossible causes:\n1. VLM server is not running\n2. CORS not configured\n3. Network connectivity issues\n4. Incorrect endpoint URL\n\nEndpoint: ${baseURLInput.value || 'default'}\n\nError: ${error.message}` };
                } else {
                    return { error: `Network error: ${error.message}\n\nPlease check the browser console for more details.` };
                }
            }
        }

        // Update performance metrics display
        function updatePerformanceMetrics(metrics) {
            const { totalTime, ttft, tokenCount, usage } = metrics;
            
            // Time to first token
            if (ttft !== undefined && ttft !== null) {
                const ttftValue = `${ttft.toFixed(0)} ms`;
                document.getElementById('ttft').textContent = ttftValue;
                document.getElementById('summaryTTFT').textContent = ttftValue;
            }
            
            // Total time
            if (totalTime !== undefined && totalTime !== null) {
                const totalTimeValue = `${(totalTime / 1000).toFixed(2)} s`;
                document.getElementById('totalTime').textContent = totalTimeValue;
                document.getElementById('summaryTotalTime').textContent = totalTimeValue;
            }
            
            // Token counts from usage
            if (usage) {
                if (usage.total_tokens !== undefined) {
                    document.getElementById('totalTokens').textContent = usage.total_tokens.toString();
                    document.getElementById('summaryTotalTokens').textContent = usage.total_tokens.toString();
                }
                if (usage.prompt_tokens !== undefined) {
                    document.getElementById('promptTokens').textContent = usage.prompt_tokens.toString();
                    document.getElementById('summaryPromptTokens').textContent = usage.prompt_tokens.toString();
                }
                if (usage.completion_tokens !== undefined) {
                    document.getElementById('responseTokens').textContent = usage.completion_tokens.toString();
                    document.getElementById('summaryResponseTokens').textContent = usage.completion_tokens.toString();
                    
                    // Calculate tokens per second based on completion tokens and total time
                    if (totalTime > 0) {
                        const tokensPerSecond = (usage.completion_tokens / (totalTime / 1000)).toFixed(2);
                        document.getElementById('tokensPerSecond').textContent = tokensPerSecond;
                        document.getElementById('summaryThroughput').textContent = `${tokensPerSecond} tokens/sec`;
                    }
                }
            }
            
            // Hide streaming indicator when final metrics are updated
            document.getElementById('streamingIndicator').style.display = 'none';
        }
        
        // Update streaming metrics in real-time
        function updateStreamingMetrics(streamMetrics) {
            const { tokenCount, ttft, elapsed } = streamMetrics;
            
            // Show streaming indicator
            document.getElementById('streamingIndicator').style.display = 'inline-flex';
            
            // Update TTFT when available
            if (ttft !== null && ttft !== undefined) {
                const ttftValue = `${ttft.toFixed(0)} ms`;
                document.getElementById('ttft').textContent = ttftValue;
                document.getElementById('summaryTTFT').textContent = ttftValue;
            }
            
            // Update elapsed time
            if (elapsed !== undefined) {
                const totalTimeValue = `${(elapsed / 1000).toFixed(2)} s`;
                document.getElementById('totalTime').textContent = totalTimeValue;
                document.getElementById('summaryTotalTime').textContent = totalTimeValue;
            }
            
            // Update approximate tokens/sec during streaming
            if (tokenCount > 0 && elapsed > 0) {
                const tokensPerSecond = (tokenCount / (elapsed / 1000)).toFixed(2);
                document.getElementById('tokensPerSecond').textContent = tokensPerSecond;
                document.getElementById('summaryThroughput').textContent = `${tokensPerSecond} tokens/sec (streaming)`;
            }
        }

        // Analyze current frame with VLM
        async function analyzeCurrentFrame() {
            console.log('=== Starting Current Frame Analysis ===');
            
            // Always capture current frame (to get the latest frame)
            console.log('Step 1: Capturing frame...');
            const captured = captureCurrentFrame();
            if (!captured || !currentFrameData) {
                console.error('‚ùå Frame capture failed');
                updateStatus('error', 'Failed to capture frame', 'exclamation-triangle');
                responseText.value = "‚ùå Failed to capture frame from video.\n\nPlease ensure:\n1. The video has loaded completely\n2. The video has played at least once\n3. Try clicking 'Capture Frame' button first\n\nCheck browser console for detailed logs.";
                return;
            }
            console.log('‚úÖ Frame captured successfully');

            const prompt = promptText.value.trim();
            if (!prompt) {
                console.error('‚ùå No prompt provided');
                updateStatus('error', 'No prompt provided', 'exclamation-triangle');
                responseText.value = "Please enter an analysis prompt.";
                return;
            }
            
            // Add timestamp context to the prompt
            const frameTime = video.currentTime.toFixed(2);
            const enhancedPrompt = `${prompt}\n\nNote: This is a SINGLE FRAME captured at timestamp ${frameTime} seconds. Analyze only what is visible in this one frame.`;
            console.log('‚úÖ Prompt validated. Frame time:', frameTime);

            try {
                console.log('Step 2: Sending to VLM with streaming...');
                updateStatus('processing', 'Analyzing with VLM...', 'brain');
                responseText.value = `üîÑ Analyzing frame at ${frameTime}s with Vision Language Model...\n\n‚è≥ Waiting for first token...\n\nStreaming enabled - results will appear in real-time.`;
                analyzeFrameBtn.disabled = true;
                analyzeFrameBtn.innerHTML = '<span class="spinner"></span><span>Streaming...</span>';
                
                // Streaming callback - updates UI as tokens arrive
                const onStreamUpdate = (partialResponse, streamMetrics) => {
                    // Update the response text area with streaming content
                    responseText.value = partialResponse;
                    
                    // Update streaming metrics in real-time
                    updateStreamingMetrics(streamMetrics);
                    
                    // Update status to show streaming is active
                    if (streamMetrics.tokenCount === 1) {
                        updateStatus('processing', 'Streaming response...', 'stream');
                    }
                };
                
                const response = await sendChatCompletionRequest(enhancedPrompt, currentFrameData, onStreamUpdate);
                
                console.log('Step 3: Processing response...');
                
                // Check if response is an error
                if (response && typeof response === 'object' && response.error) {
                    console.error('‚ùå VLM returned error:', response.error);
                    updateStatus('error', 'Analysis failed', 'exclamation-triangle');
                    responseText.value = `‚ùå Analysis failed:\n\n${response.error}\n\n=== Troubleshooting ===\n1. Check if VLM endpoint is correct\n2. Verify VLM server is running\n3. Check browser console (F12) for network errors\n4. Try "Test VLM Connection" button`;
                    return;
                }
                
                if (!response || response.length === 0) {
                    console.error('‚ùå Empty response from VLM');
                    updateStatus('error', 'Empty response', 'exclamation-triangle');
                    responseText.value = "‚ùå Received empty response from VLM.\n\nThe request succeeded but no content was returned.\nCheck browser console for details.";
                    return;
                }
                
                console.log('‚úÖ Analysis complete!');
                updateStatus('ready', 'Analysis complete', 'check-circle');
                responseText.value = `[Frame @ ${frameTime}s]\n\n${response}`;
                
            } catch (error) {
                console.error('‚ùå Unexpected error during analysis:', error);
                updateStatus('error', 'Analysis failed', 'exclamation-triangle');
                responseText.value = `‚ùå Unexpected Error:\n\n${error.message}\n\nStack trace:\n${error.stack}\n\nPlease check browser console (F12) for full details.`;
            } finally {
                analyzeFrameBtn.disabled = false;
                analyzeFrameBtn.innerHTML = '<i class="fas fa-camera"></i><span>Analyze Current Frame</span>';
                console.log('=== Analysis Complete ===');
            }
        }

        // Analyze video clip with VLM (multiple frames)
        async function analyzeVideoClip() {
            console.log('=== Starting Video Clip Analysis ===');
            
            // Check if video is loaded
            if (!video.videoWidth || !video.videoHeight) {
                updateStatus('error', 'Video not loaded yet', 'exclamation-triangle');
                responseText.value = "‚ùå Video not loaded yet.\n\nPlease wait for the video to load completely.";
                return;
            }

            const prompt = promptText.value.trim();
            if (!prompt) {
                console.error('‚ùå No prompt provided');
                updateStatus('error', 'No prompt provided', 'exclamation-triangle');
                responseText.value = "Please enter an analysis prompt.";
                return;
            }
            console.log('‚úÖ Prompt validated');

            try {
                console.log('Step 1: Extracting frames from video clip...');
                updateStatus('processing', 'Extracting frames from clip...', 'film');
                responseText.value = "üîÑ Extracting frames from video clip...\n\nPlease wait...";
                analyzeClipBtn.disabled = true;
                analyzeClipBtn.innerHTML = '<span class="spinner"></span><span>Extracting...</span>';
                
                // Capture multiple frames from the video
                const startTime = video.currentTime;
                const clipDuration = 5; // seconds
                const numFrames = 6; // Extract 6 frames
                const frameInterval = clipDuration / (numFrames - 1);
                const frames = [];
                
                // Store original time to restore later
                const originalTime = video.currentTime;
                const wasPaused = video.paused;
                
                // Pause video if playing
                if (!wasPaused) {
                    video.pause();
                }
                
                // Extract frames at intervals
                for (let i = 0; i < numFrames; i++) {
                    const targetTime = Math.min(startTime + (i * frameInterval), video.duration);
                    
                    console.log(`Seeking to ${targetTime}s (frame ${i + 1}/${numFrames})`);
                    
                    // Set video time and wait for it to seek
                    video.currentTime = targetTime;
                    
                    // Wait for video to seek to the target time
                    await new Promise((resolve) => {
                        const seekHandler = () => {
                            video.removeEventListener('seeked', seekHandler);
                            resolve();
                        };
                        video.addEventListener('seeked', seekHandler);
                        
                        // Fallback timeout in case seeked event doesn't fire
                        setTimeout(() => {
                            video.removeEventListener('seeked', seekHandler);
                            resolve();
                        }, 1000);
                    });
                    
                    // Additional wait for frame to be fully ready
                    await new Promise(resolve => setTimeout(resolve, 150));
                    
                    // Verify we're at the right time
                    const actualTime = video.currentTime;
                    console.log(`Actually at ${actualTime.toFixed(2)}s`);
                    
                    // Capture the frame
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    const context = canvas.getContext('2d');
                    context.drawImage(video, 0, 0, canvas.width, canvas.height);
                    const frameData = canvas.toDataURL('image/jpeg', 0.8);
                    
                    frames.push({
                        time: actualTime.toFixed(2),
                        data: frameData
                    });
                    
                    console.log(`üì∏ Captured frame ${i + 1}/${numFrames} @ ${actualTime.toFixed(2)}s`);
                    responseText.value = `üîÑ Extracting frames from video clip...\n\nProgress: ${i + 1}/${numFrames} frames captured\nLast frame: ${actualTime.toFixed(2)}s`;
                }
                
                // Restore original video position
                video.currentTime = originalTime;
                if (!wasPaused) {
                    video.play();
                }
                
                const endTime = parseFloat(frames[frames.length - 1].time);
                console.log(`‚úÖ Extracted ${frames.length} frames from clip (${startTime.toFixed(2)}s - ${endTime.toFixed(2)}s)`);
                console.log('Step 2: Sending to VLM with streaming...');
                
                // Build frame timestamps description
                const frameTimestamps = frames.map((f, i) => `Frame ${i + 1}: ${f.time}s`).join(', ');
                
                // Add context about the video clip to the prompt
                const enhancedPrompt = `${prompt}\n\nNote: You are analyzing a VIDEO CLIP (sequence of ${frames.length} frames) from ${startTime.toFixed(2)}s to ${endTime.toFixed(2)}s. The frames are provided in chronological order: ${frameTimestamps}. Analyze the temporal progression and identify events with their timestamps.`;
                
                updateStatus('processing', 'Analyzing with VLM...', 'brain');
                responseText.value = `üîÑ Analyzing video clip (${frames.length} frames: ${startTime.toFixed(2)}s - ${endTime.toFixed(2)}s) with Vision Language Model...\n\n‚è≥ Waiting for first token...\n\nStreaming enabled - results will appear in real-time.`;
                analyzeClipBtn.innerHTML = '<span class="spinner"></span><span>Analyzing...</span>';
                
                // Build content array with text prompt and multiple images
                const contentArray = [{ type: 'text', text: enhancedPrompt }];
                frames.forEach((frame, index) => {
                    contentArray.push({
                        type: 'image_url',
                        image_url: {
                            url: frame.data,
                            detail: "auto"
                        }
                    });
                });
                
                // Streaming callback - updates UI as tokens arrive
                const onStreamUpdate = (partialResponse, streamMetrics) => {
                    responseText.value = partialResponse;
                    updateStreamingMetrics(streamMetrics);
                    
                    if (streamMetrics.tokenCount === 1) {
                        updateStatus('processing', 'Streaming response...', 'stream');
                    }
                };
                
                // Send request with multiple frames
                const response = await sendChatCompletionRequestMultiImage(enhancedPrompt, contentArray, onStreamUpdate);
                
                console.log('Step 3: Processing response...');
                
                // Check if response is an error
                if (response && typeof response === 'object' && response.error) {
                    console.error('‚ùå VLM returned error:', response.error);
                    updateStatus('error', 'Analysis failed', 'exclamation-triangle');
                    responseText.value = `‚ùå Analysis failed:\n\n${response.error}\n\n=== Troubleshooting ===\n1. Check if VLM endpoint is correct\n2. Verify VLM server is running\n3. Check browser console (F12) for network errors\n4. Try "Test VLM Connection" button`;
                    return;
                }
                
                if (!response || response.length === 0) {
                    console.error('‚ùå Empty response from VLM');
                    updateStatus('error', 'Empty response', 'exclamation-triangle');
                    responseText.value = "‚ùå Received empty response from VLM.\n\nThe request succeeded but no content was returned.\nCheck browser console for details.";
                    return;
                }
                
                console.log('‚úÖ Clip analysis complete!');
                updateStatus('ready', 'Clip analysis complete', 'check-circle');
                responseText.value = `[Video Clip: ${startTime.toFixed(2)}s - ${endTime.toFixed(2)}s]\n[${frames.length} frames analyzed]\n\n${response}`;
                
            } catch (error) {
                console.error('‚ùå Unexpected error during clip analysis:', error);
                updateStatus('error', 'Analysis failed', 'exclamation-triangle');
                responseText.value = `‚ùå Unexpected Error:\n\n${error.message}\n\nStack trace:\n${error.stack}\n\nPlease check browser console (F12) for full details.`;
            } finally {
                analyzeClipBtn.disabled = false;
                analyzeClipBtn.innerHTML = '<i class="fas fa-film"></i><span>Analyze Video Clip</span>';
                console.log('=== Clip Analysis Complete ===');
            }
        }

        // Send streaming chat completion request with multiple images
        async function sendChatCompletionRequestMultiImage(instruction, contentArray, onStreamCallback) {
            const controller = new AbortController();
            const timeoutId = setTimeout(() => controller.abort(), 120000); // 120 seconds for multiple frames
            
            try {
                const endpoint = baseURLInput.value.trim();
                const apiUrl = endpoint ? `${endpoint}/v1/chat/completions` : '/v1/chat/completions';
                
                console.log('üì§ Preparing VLM request with multiple images...');
                console.log('   - Endpoint:', apiUrl);
                console.log('   - Number of images:', contentArray.filter(item => item.type === 'image_url').length);
                console.log('   - Instruction length:', instruction.length, 'characters');
                console.log('   - Streaming: ENABLED');
                
                const selectedModel = getSelectedModel();
                console.log('   - Model:', selectedModel);
                
                const payload = {
                    model: selectedModel,
                    max_tokens: 800,
                    temperature: 0.3,
                    messages: [
                        { 
                            role: 'user', 
                            content: contentArray
                        }
                    ],
                    stream: true,
                    stream_options: {
                        include_usage: true
                    }
                };
                
                console.log('üì§ Sending streaming request to VLM...');
                
                const requestStartTime = performance.now();
                let firstTokenTime = null;
                let tokenCount = 0;
                let fullResponse = '';
                let usage = null;
                
                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: getApiHeaders(),
                    mode: 'cors',
                    signal: controller.signal,
                    body: JSON.stringify(payload)
                });
                
                clearTimeout(timeoutId);
                
                console.log('üì• Streaming response received. Status:', response.status);
                
                if (!response.ok) {
                    const errorData = await response.text();
                    console.error('‚ùå vLLM server error response:', response.status, errorData);
                    return { error: `vLLM Server error: ${response.status}\n\n${errorData.substring(0, 500)}` };
                }
                
                // Read the streaming response
                const reader = response.body.getReader();
                const decoder = new TextDecoder();
                
                while (true) {
                    const { done, value } = await reader.read();
                    
                    if (done) {
                        console.log('‚úÖ Stream completed');
                        break;
                    }
                    
                    const chunk = decoder.decode(value, { stream: true });
                    const lines = chunk.split('\n');
                    
                    for (const line of lines) {
                        if (line.startsWith('data: ')) {
                            const data = line.substring(6).trim();
                            
                            if (data === '[DONE]') {
                                console.log('‚úÖ Stream received [DONE] signal');
                                continue;
                            }
                            
                            try {
                                const parsed = JSON.parse(data);
                                
                                if (!firstTokenTime && parsed.choices?.[0]?.delta?.content) {
                                    firstTokenTime = performance.now();
                                    const ttft = firstTokenTime - requestStartTime;
                                    console.log(`‚ö° Time to first token: ${ttft.toFixed(0)} ms`);
                                }
                                
                                const delta = parsed.choices?.[0]?.delta?.content;
                                if (delta) {
                                    fullResponse += delta;
                                    tokenCount++;
                                    
                                    if (onStreamCallback) {
                                        onStreamCallback(fullResponse, {
                                            tokenCount,
                                            ttft: firstTokenTime ? firstTokenTime - requestStartTime : null,
                                            elapsed: performance.now() - requestStartTime
                                        });
                                    }
                                }
                                
                                if (parsed.usage) {
                                    usage = parsed.usage;
                                    console.log('üìä Usage data received:', usage);
                                }
                                
                            } catch (e) {
                                console.warn('Failed to parse SSE data:', data, e);
                            }
                        }
                    }
                }
                
                const requestEndTime = performance.now();
                const totalTime = requestEndTime - requestStartTime;
                const ttft = firstTokenTime ? firstTokenTime - requestStartTime : totalTime;
                
                console.log('‚úÖ VLM Streaming completed successfully');
                console.log(`   - Total time: ${totalTime.toFixed(0)} ms`);
                console.log(`   - Time to first token: ${ttft.toFixed(0)} ms`);
                console.log(`   - Response length: ${fullResponse.length} characters`);
                console.log(`   - Streaming chunks: ${tokenCount}`);
                
                updatePerformanceMetrics({
                    totalTime: totalTime,
                    ttft: ttft,
                    tokenCount: tokenCount,
                    usage: usage || {}
                });
                
                return fullResponse;
                
            } catch (error) {
                clearTimeout(timeoutId);
                console.error('‚ùå vLLM fetch error details:', error);
                
                if (error.name === 'AbortError') {
                    return { error: 'Request timed out after 120 seconds. The VLM may be processing multiple large images or experiencing high load.' };
                } else if (error.message.includes('Failed to fetch')) {
                    return { error: `Network error: Unable to connect to VLM endpoint.\n\nPossible causes:\n1. VLM server is not running\n2. CORS not configured\n3. Network connectivity issues\n4. Incorrect endpoint URL\n\nEndpoint: ${baseURLInput.value || 'default'}\n\nError: ${error.message}` };
                } else {
                    return { error: `Network error: ${error.message}\n\nPlease check the browser console for more details.` };
                }
            }
        }

        // Initialize on page load
        window.addEventListener('DOMContentLoaded', () => {
            initTheme();
            updateStatus('ready', 'Ready to analyze', 'check-circle');
            
            // Auto-capture frame when video has loaded enough data
            video.addEventListener('loadeddata', () => {
                console.log('Video loaded, capturing initial frame');
                updateVideoStatus('ready', 'Video loaded', 'check-circle');
                // Capture first frame automatically
                captureCurrentFrame();
            });
            
            // Update status when video starts playing
            video.addEventListener('play', () => {
                updateVideoStatus('ready', 'Video playing', 'play-circle');
            });
            
            video.addEventListener('pause', () => {
                updateVideoStatus('ready', 'Video paused', 'pause-circle');
            });
            
            // Auto-capture when seeking (user scrubs to a specific time)
            video.addEventListener('seeked', () => {
                console.log('Video seeked to:', video.currentTime);
                captureCurrentFrame();
            });

            // Add fade-in animation
            const cards = document.querySelectorAll('.video-section, .controls-section, .prompt-section, .analysis-section, .header');
            cards.forEach((card, index) => {
                setTimeout(() => {
                    card.classList.add('fade-in');
                }, index * 100);
            });
        });

        // Keyboard shortcuts
        document.addEventListener('keydown', (e) => {
            if (e.key === 'Enter' && e.ctrlKey && !analyzeFrameBtn.disabled) {
                analyzeCurrentFrame();
            }
            if (e.key === ' ' && e.target.tagName !== 'TEXTAREA' && e.target.tagName !== 'INPUT') {
                e.preventDefault();
                if (video.paused) {
                    video.play();
                } else {
                    video.pause();
                }
            }
        });

        // Listen for settings updates from settings.html
        window.addEventListener('message', (event) => {
            if (event.data.type === 'settings-updated') {
                console.log('üì° Settings updated - reloading MaaS models');
                const vllmSelect = document.getElementById('vllmEndpointSelect');
                if (vllmSelect.value === 'maas') {
                    loadMaasModels();
                }
            }
        });
    </script>
</body>
</html>

